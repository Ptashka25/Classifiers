{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms as T\n",
    "from torchvision import io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trnsfrms = T.Compose(\n",
    "    [\n",
    "        T.Resize((224, 224)),\n",
    "        T.ToTensor()\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_dataset = torchvision.datasets.ImageFolder(\n",
    "    'seg_train\\seg_train',\n",
    "    transform=trnsfrms\n",
    ")\n",
    "valid_dataset = torchvision.datasets.ImageFolder(\n",
    "    'seg_test\\seg_test',\n",
    "    transform=trnsfrms\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "model.fc = nn.Linear(2048, 6)\n",
    "device = 'cuda'\n",
    "idx2class= {j: i for i, j in train_dataset.class_to_idx.items()}\n",
    "\n",
    "\n",
    "def compute_batch_accuracy(preds, labels):\n",
    "    preds_classes = torch.argmax(preds, dim=1)  # Get the class with the highest probability\n",
    "    correct_predictions = (preds_classes == labels).sum().item()\n",
    "    accuracy = correct_predictions / len(labels)\n",
    "    return accuracy\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.fc.weight.requires_grad = True\n",
    "model.fc.bias.requires_grad = True\n",
    "\n",
    "model.to(device);\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model: torch.nn.modules.container.Sequential, n_epochs: int, optimizer: torch.optim.Optimizer) -> tuple:\n",
    "  train_epoch_acc = []\n",
    "  train_epoch_losses = []\n",
    "  valid_epoch_losses = []\n",
    "  valid_epoch_acc =[]\n",
    "  for epoch in range(n_epochs):\n",
    "      loss_batch = []\n",
    "      acc_batch  = []\n",
    "      model.train()\n",
    "      for images, labels in train_loader:\n",
    "          labels = labels.type(torch.LongTensor)\n",
    "          images = images.to(device)\n",
    "          labels = labels.to(device)\n",
    "          preds = model(images)\n",
    "          loss = criterion(preds, labels)\n",
    "          loss_batch.append(loss.item())\n",
    "          acc_batch.append(compute_batch_accuracy(preds, labels))\n",
    "          optimizer.zero_grad()\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "      train_epoch_losses.append(np.mean(loss_batch))\n",
    "      train_epoch_acc.append(np.mean(acc_batch))\n",
    "      model.eval()\n",
    "      loss_batch = []\n",
    "      acc_batch  = []\n",
    "      for images, labels in valid_loader:\n",
    "          labels = labels.type(torch.LongTensor)\n",
    "          images = images.to(device)\n",
    "          labels = labels.to(device)\n",
    "          preds = model(images)\n",
    "          loss_batch.append(loss.item())\n",
    "          acc_batch.append(compute_batch_accuracy(preds, labels))\n",
    "      valid_epoch_losses.append(np.mean(loss_batch))\n",
    "      valid_epoch_acc.append(np.mean(acc_batch))\n",
    "      print(f'[Epoch {epoch:02d}] Train loss: {train_epoch_losses[-1]:.4f}, valid loss = {valid_epoch_losses[-1]:.4f} Train acc {train_epoch_acc[-1]:.4f} Valid acc {valid_epoch_acc[-1]:.4f}')\n",
    "  return train_epoch_acc, train_epoch_losses, valid_epoch_losses, valid_epoch_acc\n",
    "\n",
    "\n",
    "train_epoch_acc, train_epoch_losses, valid_epoch_losses, valid_epoch_acc = fit(model, 10, optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(path: str) -> str:\n",
    "    resize = T.Resize((224, 224))\n",
    "    img = resize(io.read_image(path)/255)\n",
    "    model.eval()\n",
    "    softmax_values = torch.softmax(model(img.unsqueeze(0).to(device)), dim=1)\n",
    "    predicted_class_index = torch.argmax(softmax_values, dim=1)\n",
    "    predicted_class = idx2class[predicted_class_index.item()]\n",
    "    return predicted_class\n",
    "\n",
    "get_prediction('seg_pred\\\\144.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'savemodel.pt')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
